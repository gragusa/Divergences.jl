module Divergences

using NaNMath
using Distances
abstract type AbstractDivergence <: PreMetric end
abstract type Divergence <: AbstractDivergence end
abstract type AbstractModifiedDivergence <: AbstractDivergence end

struct CressieRead{T} <: Divergence
    Î±::T
    function CressieRead(Î±::T) where T<:Real
        @assert (Î± != -1 && Î± != 0) "CressieRead is defined for all Î± != {-1,0}"
        a = float(Î±)
        new{eltype(a)}(a)
    end
end

struct ChiSquared  <: Divergence end
struct KullbackLeibler  <: Divergence end
struct ReverseKullbackLeibler <: Divergence end
struct Hellinger <: Divergence end

struct ModifiedDivergence{D, T} <: AbstractModifiedDivergence
    d::D
    m::NamedTuple{(:Î³â‚€, :Î³â‚, :Î³â‚‚, :Ï), Tuple{T, T, T, T}}
end

struct FullyModifiedDivergence{D, T} <: AbstractModifiedDivergence
    d::D
    m::NamedTuple{(:Î³â‚€, :Î³â‚, :Î³â‚‚, :Ï, :gâ‚€, :gâ‚, :gâ‚‚, :Ï†), Tuple{T, T, T, T, T, T, T, T}}
end

function ModifiedDivergence(D::Divergence, Ï::Real)
    @assert Ï > 1 "A ModifiedDivergence requires Ï > 1"
    Î³â‚€ = D(Ï)
    Î³â‚ = gradient(D, [Ï])[1]
    Î³â‚‚ = hessian(D, [Ï])[1]
    ModifiedDivergence(D, (Î³â‚€=Î³â‚€, Î³â‚=Î³â‚, Î³â‚‚=Î³â‚‚, Ï=Ï))
end

function FullyModifiedDivergence(D::Divergence, Ï†::Real, Ï::Real)
    @assert Ï > 1 "A ModifiedDivergence requires Ï > 1"
    @assert Ï† < 1 && Ï† > 0 "A ModifiedDivergence requires  Ï† âˆˆ (0,1)"
    Î³â‚€ = D(Ï)
    Î³â‚ = gradient(D, [Ï])[1]
    Î³â‚‚ = hessian(D, [Ï])[1]
    gâ‚€ = D(Ï†)
    gâ‚ = gradient(D, [Ï†])[1]
    gâ‚‚ = hessian(D, [Ï†])[1]
    FullyModifiedDivergence(D, (Î³â‚€=Î³â‚€, Î³â‚=Î³â‚, Î³â‚‚=Î³â‚‚, Ï=Ï, gâ‚€=gâ‚€, gâ‚=gâ‚, gâ‚‚=gâ‚‚, Ï†=Ï†))
end

for div âˆˆ (KullbackLeibler, ReverseKullbackLeibler, Hellinger, CressieRead, ChiSquared, ModifiedDivergence, FullyModifiedDivergence)
    @eval begin
        function (f::$div)(p::Real, q::Real)
            return Î³(f, p, q)
        end
    end
end

for div âˆˆ (KullbackLeibler, ReverseKullbackLeibler, Hellinger, CressieRead, ChiSquared, ModifiedDivergence, FullyModifiedDivergence)
    @eval begin
        function (f::$div)(p::Real)
            return Î³(f, p)
        end
    end
end

for div âˆˆ (KullbackLeibler, ReverseKullbackLeibler, Hellinger, CressieRead, ChiSquared, ModifiedDivergence, FullyModifiedDivergence)
    @eval begin
        function (f::$div)(a::AbstractArray, b::AbstractArray)
            return sum(Î³(f, a./b).*b)
        end
    end
end

for div âˆˆ (KullbackLeibler, ReverseKullbackLeibler, Hellinger, CressieRead, ChiSquared, ModifiedDivergence, FullyModifiedDivergence)
    @eval begin
        function (f::$div)(a::AbstractArray)
            return sum(Î³(f, a))
        end
    end
end

function Distances.evaluate(f::AbstractDivergence, a::AbstractArray)
    return sum(f.(a))
end

function Distances.evaluate(f::AbstractDivergence, a::AbstractArray, b::AbstractArray)
    return sum(f.(a./b).*b)
end

include("divs.jl")




export
    # KL
    KullbackLeibler,
    # RKL
    ReverseKullbackLeibler,
    # HD
    Hellinger,
    # CR
    CressieRead,
    # 
    ChiSquared,
    # Modified
    ModifiedDivergence,
    # FullyModified
    FullyModifiedDivergence,
    # Abbr.
    ğ’¦â„’,
    â„¬ğ“Šğ“‡â„Š,
    ğ’â„›,
    â„‹ğ’Ÿ,
    Ï‡Â²
end
